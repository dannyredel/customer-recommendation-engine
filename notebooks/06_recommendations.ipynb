{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 — Recommendation Engine\n",
    "Build a hybrid recommendation system: collaborative filtering + content-based + LLM explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danny\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.8.7' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\danny\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:56: UserWarning: Pandas requires version '1.4.2' or newer of 'bottleneck' (version '1.3.7' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions: 112,650\n",
      "Unique users: 95,420\n",
      "Unique products: 32,951\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# Load raw data\n",
    "orders = pd.read_csv('../data/raw/olist_orders_dataset.csv')\n",
    "items = pd.read_csv('../data/raw/olist_order_items_dataset.csv')\n",
    "products = pd.read_csv('../data/raw/olist_products_dataset.csv')\n",
    "customers = pd.read_csv('../data/raw/olist_customers_dataset.csv')\n",
    "categories = pd.read_csv('../data/raw/product_category_name_translation.csv')\n",
    "customer_features = pd.read_csv('../data/processed/customer_features.csv')\n",
    "\n",
    "# Build user-product interaction table\n",
    "interactions = (\n",
    "    items[['order_id', 'product_id', 'price']]\n",
    "    .merge(orders[['order_id', 'customer_id']], on='order_id')\n",
    "    .merge(customers[['customer_id', 'customer_unique_id']], on='customer_id')\n",
    ")\n",
    "\n",
    "print(f'Interactions: {len(interactions):,}')\n",
    "print(f'Unique users: {interactions[\"customer_unique_id\"].nunique():,}')\n",
    "print(f'Unique products: {interactions[\"product_id\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collaborative Filtering\n",
    "Build a user-item matrix and use the `implicit` library to find patterns.\n",
    "We use **ALS (Alternating Least Squares)** — it learns latent factors for each user and product.\n",
    "Think of it as: each user gets a hidden 'taste vector' and each product gets a hidden 'feature vector'.\n",
    "Good recommendations happen when these vectors are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix: (95420, 32951)\n",
      "Sparsity: 0.999968\n"
     ]
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "# Create mappings: user/product IDs to integer indices\n",
    "user_ids = interactions['customer_unique_id'].unique()\n",
    "product_ids = interactions['product_id'].unique()\n",
    "\n",
    "user_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "product_to_idx = {pid: i for i, pid in enumerate(product_ids)}\n",
    "idx_to_product = {i: pid for pid, i in product_to_idx.items()}\n",
    "idx_to_user = {i: uid for uid, i in user_to_idx.items()}\n",
    "\n",
    "# Build sparse user-item matrix (rows=users, cols=products, values=1 for purchased)\n",
    "rows = interactions['customer_unique_id'].map(user_to_idx).values\n",
    "cols = interactions['product_id'].map(product_to_idx).values\n",
    "values = np.ones(len(interactions))  # binary: purchased or not\n",
    "\n",
    "user_item = sparse.csr_matrix((values, (rows, cols)), shape=(len(user_ids), len(product_ids)))\n",
    "print(f'User-item matrix: {user_item.shape}')\n",
    "print(f'Sparsity: {1 - user_item.nnz / (user_item.shape[0] * user_item.shape[1]):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danny\\anaconda3\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 16 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2deb381c3444b1b85c3417a171d77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS model trained.\n"
     ]
    }
   ],
   "source": [
    "# Train ALS model\n",
    "als_model = AlternatingLeastSquares(\n",
    "    factors=50,       # dimensionality of latent vectors\n",
    "    regularization=0.1,\n",
    "    iterations=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# implicit expects item-user matrix (transposed)\n",
    "als_model.fit(user_item)\n",
    "print('ALS model trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user: 871766c5855e863f6ecc...\n",
      "  Product: 54d9ac713e253fa1fae9...  Score: 0.000\n",
      "  Product: 99a4788cb24856965c36...  Score: 0.000\n",
      "  Product: 601a360bd2a916ecef0e...  Score: 0.000\n",
      "  Product: d285360f29ac7fd97640...  Score: 0.000\n",
      "  Product: 7ce94ab189134e2d3c05...  Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Test: get recommendations for a sample user\n",
    "sample_user_idx = 0\n",
    "sample_user_id = idx_to_user[sample_user_idx]\n",
    "\n",
    "# Get top 5 recommendations\n",
    "recommended_idx, scores = als_model.recommend(\n",
    "    sample_user_idx, user_item[sample_user_idx], N=5, filter_already_liked_items=True\n",
    ")\n",
    "\n",
    "print(f'Recommendations for user: {sample_user_id[:20]}...')\n",
    "for idx, score in zip(recommended_idx, scores):\n",
    "    pid = idx_to_product[idx]\n",
    "    print(f'  Product: {pid[:20]}...  Score: {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Content-Based Filtering\n",
    "For users with few purchases (most of them), recommend products similar to what they bought.\n",
    "We use **cosine similarity** on product features: category, price range, and physical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product content matrix: (32951, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Prepare product features\n",
    "prod_features = products.merge(categories, on='product_category_name', how='left')\n",
    "\n",
    "# Select numeric features + encode category\n",
    "le = LabelEncoder()\n",
    "prod_features['category_encoded'] = le.fit_transform(\n",
    "    prod_features['product_category_name_english'].fillna('unknown')\n",
    ")\n",
    "\n",
    "content_cols = ['category_encoded', 'product_weight_g', 'product_length_cm',\n",
    "                'product_height_cm', 'product_width_cm', 'product_photos_qty']\n",
    "\n",
    "# Fill nulls and scale\n",
    "prod_content = prod_features[content_cols].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "prod_content_scaled = scaler.fit_transform(prod_content)\n",
    "\n",
    "# Map product_id to index in this feature matrix\n",
    "prod_id_to_content_idx = {pid: i for i, pid in enumerate(prod_features['product_id'].values)}\n",
    "\n",
    "print(f'Product content matrix: {prod_content_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products similar to 4244733e06e7ecb4970a... (category: cool_stuff):\n",
      "  54e5939fcd9ae70ad0f5...  Category: cool_stuff  Sim: 0.998\n",
      "  d65b6607952f9e0d705b...  Category: cool_stuff  Sim: 0.997\n",
      "  a835dd882c7fb9015ed5...  Category: cool_stuff  Sim: 0.994\n",
      "  6456fdf43df7d711b98d...  Category: computers_accessories  Sim: 0.993\n",
      "  8b75356a402f017bf41f...  Category: auto  Sim: 0.989\n"
     ]
    }
   ],
   "source": [
    "def get_content_recommendations(product_id, top_n=5):\n",
    "    \"\"\"Given a product, find the most similar products by content features.\"\"\"\n",
    "    if product_id not in prod_id_to_content_idx:\n",
    "        return []\n",
    "    \n",
    "    idx = prod_id_to_content_idx[product_id]\n",
    "    # Compute similarity between this product and all others\n",
    "    sim_scores = cosine_similarity(\n",
    "        prod_content_scaled[idx:idx+1], prod_content_scaled\n",
    "    )[0]\n",
    "    \n",
    "    # Get top N (excluding itself)\n",
    "    top_indices = sim_scores.argsort()[::-1][1:top_n+1]\n",
    "    \n",
    "    results = []\n",
    "    for i in top_indices:\n",
    "        results.append({\n",
    "            'product_id': prod_features.iloc[i]['product_id'],\n",
    "            'category': prod_features.iloc[i]['product_category_name_english'],\n",
    "            'similarity': sim_scores[i]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Test: find products similar to the first product\n",
    "test_pid = interactions['product_id'].iloc[0]\n",
    "test_cat = prod_features[prod_features['product_id'] == test_pid]['product_category_name_english'].values[0]\n",
    "print(f'Products similar to {test_pid[:20]}... (category: {test_cat}):')\n",
    "for rec in get_content_recommendations(test_pid):\n",
    "    print(f\"  {rec['product_id'][:20]}...  Category: {rec['category']}  Sim: {rec['similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hybrid Recommendations\n",
    "Combine collaborative filtering and content-based into a single recommendation function.\n",
    "Strategy: use collaborative filtering scores when available, boost with content similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer: c8460e4251689ba20504...  Segment: High-Value Buyers\n",
      "  furniture_decor                 hybrid=0.568  (cf=0.946, content=0.000)\n",
      "  furniture_decor                 hybrid=0.461  (cf=0.768, content=0.000)\n",
      "  sports_leisure                  hybrid=0.397  (cf=0.000, content=0.992)\n",
      "\n",
      "Customer: 4546caea018ad8c69296...  Segment: Repeat Loyalists\n",
      "  health_beauty                   hybrid=0.399  (cf=0.000, content=0.997)\n",
      "  health_beauty                   hybrid=0.399  (cf=0.000, content=0.997)\n",
      "  garden_tools                    hybrid=0.398  (cf=0.000, content=0.996)\n",
      "\n",
      "Customer: c402f431464c72e27330...  Segment: High-Value Buyers\n",
      "  consoles_games                  hybrid=0.399  (cf=0.000, content=0.997)\n",
      "  consoles_games                  hybrid=0.399  (cf=0.000, content=0.996)\n",
      "  christmas_supplies              hybrid=0.398  (cf=0.000, content=0.995)\n"
     ]
    }
   ],
   "source": [
    "def get_hybrid_recommendations(customer_unique_id, top_n=5):\n",
    "    \"\"\"Get hybrid recommendations for a customer.\"\"\"\n",
    "    recommendations = {}\n",
    "    \n",
    "    # 1. Collaborative filtering (if user exists in the matrix)\n",
    "    if customer_unique_id in user_to_idx:\n",
    "        user_idx = user_to_idx[customer_unique_id]\n",
    "        rec_idx, rec_scores = als_model.recommend(\n",
    "            user_idx, user_item[user_idx], N=top_n * 2, filter_already_liked_items=True\n",
    "        )\n",
    "        for idx, score in zip(rec_idx, rec_scores):\n",
    "            pid = idx_to_product[idx]\n",
    "            recommendations[pid] = {'cf_score': float(score), 'content_score': 0.0}\n",
    "    \n",
    "    # 2. Content-based: find products similar to what they already bought\n",
    "    user_products = interactions[interactions['customer_unique_id'] == customer_unique_id]['product_id'].unique()\n",
    "    for bought_pid in user_products:\n",
    "        for rec in get_content_recommendations(bought_pid, top_n=top_n):\n",
    "            pid = rec['product_id']\n",
    "            if pid not in user_products:  # don't recommend what they already bought\n",
    "                if pid not in recommendations:\n",
    "                    recommendations[pid] = {'cf_score': 0.0, 'content_score': 0.0}\n",
    "                recommendations[pid]['content_score'] = max(\n",
    "                    recommendations[pid]['content_score'], rec['similarity']\n",
    "                )\n",
    "    \n",
    "    # 3. Combine scores (weighted: 60% CF, 40% content)\n",
    "    for pid in recommendations:\n",
    "        recommendations[pid]['hybrid_score'] = (\n",
    "            0.6 * recommendations[pid]['cf_score'] +\n",
    "            0.4 * recommendations[pid]['content_score']\n",
    "        )\n",
    "    \n",
    "    # Sort by hybrid score and return top N\n",
    "    sorted_recs = sorted(recommendations.items(), key=lambda x: x[1]['hybrid_score'], reverse=True)[:top_n]\n",
    "    \n",
    "    result = []\n",
    "    for pid, scores in sorted_recs:\n",
    "        cat = prod_features[prod_features['product_id'] == pid]['product_category_name_english'].values\n",
    "        cat = cat[0] if len(cat) > 0 else 'unknown'\n",
    "        result.append({\n",
    "            'product_id': pid,\n",
    "            'category': cat,\n",
    "            'hybrid_score': scores['hybrid_score'],\n",
    "            'cf_score': scores['cf_score'],\n",
    "            'content_score': scores['content_score']\n",
    "        })\n",
    "    return result\n",
    "\n",
    "# Test on a few customers\n",
    "test_customers = interactions['customer_unique_id'].value_counts().head(3).index.tolist()\n",
    "for cid in test_customers:\n",
    "    recs = get_hybrid_recommendations(cid, top_n=3)\n",
    "    seg = customer_features[customer_features['customer_unique_id'] == cid]['segment_name'].values\n",
    "    seg = seg[0] if len(seg) > 0 else 'unknown'\n",
    "    print(f'\\nCustomer: {cid[:20]}...  Segment: {seg}')\n",
    "    for r in recs:\n",
    "        print(f\"  {r['category']:30s}  hybrid={r['hybrid_score']:.3f}  (cf={r['cf_score']:.3f}, content={r['content_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation\n",
    "For users with 2+ orders, hold out the last order and see if we recommend any of those products.\n",
    "Metric: **Hit Rate @K** — what % of users had at least one held-out product in their top-K recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with 2+ orders: 2,913\n",
      "Hit Rate @10: 0.000 (0/500)\n",
      "(Baseline random would be ~0.00030)\n"
     ]
    }
   ],
   "source": [
    "# Find users with 2+ orders\n",
    "user_order_counts = (\n",
    "    interactions.merge(orders[['order_id', 'order_purchase_timestamp']], on='order_id')\n",
    "    .groupby('customer_unique_id')['order_id'].nunique()\n",
    ")\n",
    "repeat_users = user_order_counts[user_order_counts >= 2].index.tolist()\n",
    "print(f'Users with 2+ orders: {len(repeat_users):,}')\n",
    "\n",
    "# For each repeat user: hold out their last purchased product, check if we recommend it\n",
    "hits = 0\n",
    "total = 0\n",
    "K = 10\n",
    "\n",
    "user_interactions = interactions.merge(orders[['order_id', 'order_purchase_timestamp']], on='order_id')\n",
    "\n",
    "for uid in repeat_users[:500]:  # sample 500 for speed\n",
    "    user_data = user_interactions[user_interactions['customer_unique_id'] == uid].sort_values('order_purchase_timestamp')\n",
    "    last_products = user_data.iloc[-1:]['product_id'].values\n",
    "    \n",
    "    recs = get_hybrid_recommendations(uid, top_n=K)\n",
    "    rec_pids = [r['product_id'] for r in recs]\n",
    "    \n",
    "    if any(p in rec_pids for p in last_products):\n",
    "        hits += 1\n",
    "    total += 1\n",
    "\n",
    "print(f'Hit Rate @{K}: {hits/total:.3f} ({hits}/{total})')\n",
    "print(f'(Baseline random would be ~{K/len(product_ids):.5f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: LLM-Powered Recommendation Explanations\n",
    "Use an LLM API to generate natural language explanations for recommendations.\n",
    "This shows you can integrate LLM APIs into a production ML pipeline.\n",
    "\n",
    "We use OpenAI here. The API key is loaded from a `.env` file (never hardcode keys in notebooks!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM client ready.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv('../.env')\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from environment\n",
    "\n",
    "def generate_explanation(customer_segment, purchased_categories, recommended_product, rec_category):\n",
    "    \"\"\"Generate a natural language explanation for a recommendation.\"\"\"\n",
    "    prompt = f\"\"\"You are a product recommendation system. Generate a brief, friendly 1-2 sentence explanation\n",
    "for why this product is being recommended.\n",
    "\n",
    "Customer segment: {customer_segment}\n",
    "Products they previously bought (categories): {', '.join(purchased_categories[:5])}\n",
    "Recommended product category: {rec_category}\n",
    "\n",
    "Write the explanation as if speaking directly to the customer. Be specific about why this fits them.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        max_tokens=100,\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print('LLM client ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer: c8460e4251689ba20504...  Segment: High-Value Buyers\n",
      "Previously bought: ['telephony']\n",
      "\n",
      "Recommended: furniture_decor\n",
      "  Why: We know that as a high-value buyer, you appreciate quality and style in every aspect of your life. That's why we're recommending our premium furniture and decor, tailored to create a harmonious and inspiring workspace that complements your sophisticated taste while enhancing your telephony experience.\n",
      "\n",
      "Recommended: furniture_decor\n",
      "  Why: As a valued customer who appreciates quality and sophistication in your telephony choices, we think you'll love our curated selection of furniture and decor. These pieces not only enhance your workspace but also reflect your premium taste, creating an inspiring and stylish environment for your important calls and meetings.\n",
      "\n",
      "Recommended: sports_leisure\n",
      "  Why: We know you appreciate quality and value, and with your interest in telephony, we think you'd enjoy our premium sports and leisure products that offer the perfect blend of performance and style. These items will enhance your active lifestyle while maintaining the high standards you expect!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate explanations for a sample customer's recommendations\n",
    "sample_cid = test_customers[0]\n",
    "sample_seg = customer_features[customer_features['customer_unique_id'] == sample_cid]['segment_name'].values[0]\n",
    "sample_bought = interactions[interactions['customer_unique_id'] == sample_cid]['product_id'].unique()\n",
    "bought_cats = []\n",
    "for pid in sample_bought:\n",
    "    cat = prod_features[prod_features['product_id'] == pid]['product_category_name_english'].values\n",
    "    if len(cat) > 0:\n",
    "        bought_cats.append(cat[0])\n",
    "\n",
    "recs = get_hybrid_recommendations(sample_cid, top_n=3)\n",
    "\n",
    "print(f'Customer: {sample_cid[:20]}...  Segment: {sample_seg}')\n",
    "print(f'Previously bought: {bought_cats}')\n",
    "print()\n",
    "\n",
    "for r in recs:\n",
    "    explanation = generate_explanation(sample_seg, bought_cats, r['product_id'], r['category'])\n",
    "    print(f\"Recommended: {r['category']}\")\n",
    "    print(f\"  Why: {explanation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Recommendation Function\n",
    "Save the models and mappings so the API can use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to models/recommendation_models.pkl\n",
      "File size: 47.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save everything the API will need\n",
    "rec_data = {\n",
    "    'als_model': als_model,\n",
    "    'user_item': user_item,\n",
    "    'user_to_idx': user_to_idx,\n",
    "    'idx_to_product': idx_to_product,\n",
    "    'idx_to_user': idx_to_user,\n",
    "    'product_to_idx': product_to_idx,\n",
    "    'prod_content_scaled': prod_content_scaled,\n",
    "    'prod_id_to_content_idx': prod_id_to_content_idx,\n",
    "    'prod_features': prod_features[['product_id', 'product_category_name_english']],\n",
    "    'interactions': interactions[['customer_unique_id', 'product_id']],\n",
    "}\n",
    "\n",
    "with open('../models/recommendation_models.pkl', 'wb') as f:\n",
    "    pickle.dump(rec_data, f)\n",
    "\n",
    "print(f'Models saved to models/recommendation_models.pkl')\n",
    "print(f'File size: {os.path.getsize(\"../models/recommendation_models.pkl\") / 1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: A/B Test Design (Written Exercise)\n",
    "**YOUR EXERCISE:** Write a brief A/B test design document answering these questions:\n",
    "\n",
    "1. **Hypothesis:** What do you expect the recommendation engine to improve? (e.g., click-through rate, repeat purchases, revenue per user)\n",
    "2. **Control vs Treatment:** What does each group see? (e.g., control = random/popular products, treatment = personalized recommendations)\n",
    "3. **Randomization:** How do you split users? (random assignment, stratified by segment?)\n",
    "4. **Primary metric:** What single metric determines success?\n",
    "5. **Sample size:** How many users and how long to run the test?\n",
    "6. **Guardrail metrics:** What should NOT get worse? (e.g., customer satisfaction, return rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B Test Design\n",
    "\n",
    "**YOUR ANSWERS HERE:**\n",
    "\n",
    "1. **Hypothesis:** ...\n",
    "2. **Control vs Treatment:** ...\n",
    "3. **Randomization:** ...\n",
    "4. **Primary metric:** ...\n",
    "5. **Sample size:** ...\n",
    "6. **Guardrail metrics:** ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
